{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('operators_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operator_address</th>\n",
       "      <th>operator_id</th>\n",
       "      <th>percentage</th>\n",
       "      <th>quorum_id</th>\n",
       "      <th>total_batches</th>\n",
       "      <th>total_unsigned_batches</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x00107cfdeaddc0a3160ed2f6fedd627f313e7b1a</td>\n",
       "      <td>0x57309111be2293fbcfd77e8479a4f2570f8956aae8cd...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1717934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x006b988f89579e5842bcd029955dfbfc334b6826</td>\n",
       "      <td>0x852f5c1ecf96472bb48fc8e9373b40c74ac3e2cdf32a...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1717934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x01a7c2568693d65a367fde016b48c63f6673d4dc</td>\n",
       "      <td>0x7e06688af02ac562ee27c843b7e688eb1c67b469b3e6...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1717934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x033bfb405e809a303df875a6e018f1a64e5dbae9</td>\n",
       "      <td>0x2e2ee953aa3c2a499640270eaaf2ba1973265f7e0d0b...</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>1717934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x033bfb405e809a303df875a6e018f1a64e5dbae9</td>\n",
       "      <td>0x2e2ee953aa3c2a499640270eaaf2ba1973265f7e0d0b...</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>1717934400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             operator_address  \\\n",
       "0  0x00107cfdeaddc0a3160ed2f6fedd627f313e7b1a   \n",
       "1  0x006b988f89579e5842bcd029955dfbfc334b6826   \n",
       "2  0x01a7c2568693d65a367fde016b48c63f6673d4dc   \n",
       "3  0x033bfb405e809a303df875a6e018f1a64e5dbae9   \n",
       "4  0x033bfb405e809a303df875a6e018f1a64e5dbae9   \n",
       "\n",
       "                                         operator_id  percentage  quorum_id  \\\n",
       "0  0x57309111be2293fbcfd77e8479a4f2570f8956aae8cd...      0.0000          0   \n",
       "1  0x852f5c1ecf96472bb48fc8e9373b40c74ac3e2cdf32a...      0.0000          1   \n",
       "2  0x7e06688af02ac562ee27c843b7e688eb1c67b469b3e6...      0.0000          1   \n",
       "3  0x2e2ee953aa3c2a499640270eaaf2ba1973265f7e0d0b...      0.0625          0   \n",
       "4  0x2e2ee953aa3c2a499640270eaaf2ba1973265f7e0d0b...      0.0625          1   \n",
       "\n",
       "   total_batches  total_unsigned_batches   timestamp  \n",
       "0            144                       0  1717934400  \n",
       "1            144                       0  1717934400  \n",
       "2            144                       0  1717934400  \n",
       "3            144                       9  1717934400  \n",
       "4            144                       9  1717934400  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13181 entries, 0 to 13180\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   operator_address        13181 non-null  object \n",
      " 1   operator_id             13181 non-null  object \n",
      " 2   percentage              13181 non-null  float64\n",
      " 3   quorum_id               13181 non-null  int64  \n",
      " 4   total_batches           13181 non-null  int64  \n",
      " 5   total_unsigned_batches  13181 non-null  int64  \n",
      " 6   timestamp               13181 non-null  int64  \n",
      "dtypes: float64(1), int64(4), object(2)\n",
      "memory usage: 721.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change operator address to string\n",
    "df['operator_address'] = df['operator_address'].astype(str)\n",
    "df['operator_id'] = df['operator_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13181, 263)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(df['operator_address'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows in which operator_address and timestamp are same and quorum_id is 1. keep the one in which quoram_id is 0\n",
    "df = df.drop_duplicates(subset=['operator_address', 'timestamp'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9732, 263)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df), len(df['operator_address'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of all percentage of a certain operator\n",
    "df['total_percentage'] = df.groupby('operator_address')['percentage'].transform('sum')\n",
    "\n",
    "# frequency of each operator\n",
    "df['frequency'] = df.groupby('operator_address')['operator_address'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operator_address</th>\n",
       "      <th>operator_id</th>\n",
       "      <th>percentage</th>\n",
       "      <th>quorum_id</th>\n",
       "      <th>total_batches</th>\n",
       "      <th>total_unsigned_batches</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>total_percentage</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x00107cfdeaddc0a3160ed2f6fedd627f313e7b1a</td>\n",
       "      <td>0x57309111be2293fbcfd77e8479a4f2570f8956aae8cd...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1717934400</td>\n",
       "      <td>0.019536</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x006b988f89579e5842bcd029955dfbfc334b6826</td>\n",
       "      <td>0x852f5c1ecf96472bb48fc8e9373b40c74ac3e2cdf32a...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1717934400</td>\n",
       "      <td>0.010856</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x01a7c2568693d65a367fde016b48c63f6673d4dc</td>\n",
       "      <td>0x7e06688af02ac562ee27c843b7e688eb1c67b469b3e6...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1717934400</td>\n",
       "      <td>0.007636</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x033bfb405e809a303df875a6e018f1a64e5dbae9</td>\n",
       "      <td>0x2e2ee953aa3c2a499640270eaaf2ba1973265f7e0d0b...</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>9</td>\n",
       "      <td>1717934400</td>\n",
       "      <td>0.267125</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0x047438c5ceaa6d47e8691b51f5b34c6d41a00e3d</td>\n",
       "      <td>0xdbf03be4c90917ec42220446cee2b1226ac96fd074c5...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1717934400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             operator_address  \\\n",
       "0  0x00107cfdeaddc0a3160ed2f6fedd627f313e7b1a   \n",
       "1  0x006b988f89579e5842bcd029955dfbfc334b6826   \n",
       "2  0x01a7c2568693d65a367fde016b48c63f6673d4dc   \n",
       "3  0x033bfb405e809a303df875a6e018f1a64e5dbae9   \n",
       "5  0x047438c5ceaa6d47e8691b51f5b34c6d41a00e3d   \n",
       "\n",
       "                                         operator_id  percentage  quorum_id  \\\n",
       "0  0x57309111be2293fbcfd77e8479a4f2570f8956aae8cd...      0.0000          0   \n",
       "1  0x852f5c1ecf96472bb48fc8e9373b40c74ac3e2cdf32a...      0.0000          1   \n",
       "2  0x7e06688af02ac562ee27c843b7e688eb1c67b469b3e6...      0.0000          1   \n",
       "3  0x2e2ee953aa3c2a499640270eaaf2ba1973265f7e0d0b...      0.0625          0   \n",
       "5  0xdbf03be4c90917ec42220446cee2b1226ac96fd074c5...      0.0000          1   \n",
       "\n",
       "   total_batches  total_unsigned_batches   timestamp  total_percentage  \\\n",
       "0            144                       0  1717934400          0.019536   \n",
       "1            144                       0  1717934400          0.010856   \n",
       "2            144                       0  1717934400          0.007636   \n",
       "3            144                       9  1717934400          0.267125   \n",
       "5            144                       0  1717934400          0.000000   \n",
       "\n",
       "   frequency  \n",
       "0         52  \n",
       "1         17  \n",
       "2         29  \n",
       "3         20  \n",
       "5         29  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by timestamp\n",
    "df = df.sort_values(by='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pj/vyqltmgj79xghgpb38_96m040000gn/T/ipykernel_83346/2820544988.py:17: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df = df.groupby('operator_address').apply(create_lag_features, lag=7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the CSV file\n",
    "# df = pd.read_csv('operator_data.csv')\n",
    "\n",
    "# Function to create lag features\n",
    "def create_lag_features(df, lag=1):\n",
    "    for i in range(1, lag + 1):\n",
    "        df[f'lag_{i}'] = df['percentage'].shift(i)\n",
    "    return df\n",
    "\n",
    "# Create lag features for the past 5 days\n",
    "df = df.groupby('operator_address').apply(create_lag_features, lag=7)\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "# print(df.head())\n",
    " \n",
    "# Define features and target\n",
    "# features = [col for col in df.columns if 'lag_' in col]\n",
    "features = ['lag_1', 'lag_2', 'lag_3', 'lag_4', 'lag_5', 'lag_6', 'lag_7', 'quorum_id', 'total_batches', 'total_unsigned_batches', 'frequency', 'total_percentage', 'timestamp']\n",
    "target = 'percentage'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_df = df[df['timestamp'] < 1717934400]\n",
    "test_df = df[df['timestamp'] >= 1717934400]\n",
    "\n",
    "X_train = train_df[features]\n",
    "Y_train = train_df[target]\n",
    "X_test = test_df[features]\n",
    "Y_test = test_df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    Y_train: pd.DataFrame,\n",
    "    Y_test: pd.DataFrame,\n",
    "):\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(X_train.shape[1], 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 1),\n",
    "    )\n",
    "\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.RMSprop(model.parameters())\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(Y_train.values.reshape(-1, 1), dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "\n",
    "    # Training loop\n",
    "    epochs_trial = np.arange(100, 400, 4)\n",
    "    batch_trial = np.arange(100, 400, 4)\n",
    "    DL_pred = []\n",
    "    DL_RMSE = []\n",
    "    for i, j, k in zip(range(4), epochs_trial, batch_trial):\n",
    "        for epoch in range(j):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_tensor)\n",
    "            loss = criterion(outputs, y_tensor)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            DL_predict = model(X_test_tensor).numpy()\n",
    "            DL_RMSE.append(\n",
    "                np.sqrt(mse(Y_test.values / 100, DL_predict.flatten() / 100))\n",
    "            )\n",
    "            DL_pred.append(DL_predict)\n",
    "            print(\"DL_RMSE_{}:{:.6f}\".format(i + 1, DL_RMSE[i]))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 4255, 4474)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test), len(X_train), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_to_onnx(\n",
    "    model: nn.Module, X_train: pd.DataFrame, save_path=\"torch_operator_model\"\n",
    "):\n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Dummy input matching the input size\n",
    "    sample_input = torch.randn(\n",
    "        1, X_train.shape[1]\n",
    "    )  # Replace 1 with the batch size you'd like to use\n",
    "\n",
    "    # Specify the path to save the ONNX model\n",
    "    onnx_file_path = save_path + \".onnx\"\n",
    "\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        sample_input,\n",
    "        onnx_file_path,\n",
    "        export_params=True,\n",
    "        opset_version=10,\n",
    "        do_constant_folding=True,\n",
    "        input_names=[\"input\"],\n",
    "        output_names=[\"output\"],\n",
    "        dynamic_axes={\n",
    "            \"input\": {0: \"batch_size\"},\n",
    "            \"output\": {0: \"batch_size\"},\n",
    "        },\n",
    "    )\n",
    "    print(f\"Saved serialized ONNX model to {onnx_file_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL_RMSE_1:0.040714\n",
      "DL_RMSE_2:0.040714\n",
      "DL_RMSE_3:0.058086\n",
      "DL_RMSE_4:0.058086\n",
      "Saved serialized ONNX model to torch_operator_model.onnx.\n"
     ]
    }
   ],
   "source": [
    "model = train_model(X_train, X_test, Y_train, Y_test)\n",
    "serialize_to_onnx(model, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:10:04\u001b[0m.\u001b[1;36m029\u001b[0m\u001b[1m]\u001b[0m No model id provided, checking if model exists ‚úÖ\n",
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:10:04\u001b[0m.\u001b[1;36m031\u001b[0m\u001b[1m]\u001b[0m Model name is: torch_operator_model\n",
      "\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:10:07\u001b[0m.\u001b[1;36m631\u001b[0m\u001b[1m]\u001b[0m Model Created with id -> \u001b[1;36m818\u001b[0m! ‚úÖ\n",
      "\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:10:10\u001b[0m.\u001b[1;36m382\u001b[0m\u001b[1m]\u001b[0m Version Created with id -> \u001b[1;36m1\u001b[0m! ‚úÖ\n",
      "\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:10:10\u001b[0m.\u001b[1;36m383\u001b[0m\u001b[1m]\u001b[0m Sending model for transpilation ‚úÖ \n",
      "\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:10:57\u001b[0m.\u001b[1;36m481\u001b[0m\u001b[1m]\u001b[0m Transpilation is fully compatible. Version compiled and Sierra is saved at Giza ‚úÖ\n",
      "\u001b[2K\u001b[32m‚†á\u001b[0m Transpiling Model...\n",
      "\u001b[1A\u001b[2K\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:11:00\u001b[0m.\u001b[1;36m866\u001b[0m\u001b[1m]\u001b[0m Downloading model ‚úÖ\n",
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:11:00\u001b[0m.\u001b[1;36m877\u001b[0m\u001b[1m]\u001b[0m model saved at: verifiable_nn\n"
     ]
    }
   ],
   "source": [
    "!giza transpile torch_operator_model.onnx --output-path verifiable_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K‚ñ∞‚ñ∞‚ñ∞‚ñ∞‚ñ∞‚ñ∞‚ñ∞ Creating endpoint!t!\n",
      "\u001b[?25h\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:15:20\u001b[0m.\u001b[1;36m497\u001b[0m\u001b[1m]\u001b[0m Endpoint is successful ‚úÖ\n",
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:15:20\u001b[0m.\u001b[1;36m501\u001b[0m\u001b[1m]\u001b[0m Endpoint created with id -> \u001b[1;36m371\u001b[0m ‚úÖ\n",
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:15:20\u001b[0m.\u001b[1;36m502\u001b[0m\u001b[1m]\u001b[0m Endpoint created with endpoint URL: \u001b[4;94mhttps://endpoint-ashq-818-1-7f03ffa7-7i3yxzspbq-ew.a.run.app\u001b[0m üéâ\n"
     ]
    }
   ],
   "source": [
    "!giza endpoints deploy --model-id 818 --version-id 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "input =  np.array([X_test.iloc[0]]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.4400000e+02, 0.0000000e+00, 5.3000000e+01, 7.5797118e-02,\n",
       "        1.7179343e+09]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error occurred in predict: 500 Server Error: Internal Server Error for url: https://endpoint-ashq-818-1-7f03ffa7-7i3yxzspbq-ew.a.run.app/cairo_run\n",
      "Deployment predict error: Running the Cairo  programm failed\n",
      "An error occurred in predict: 500 Server Error: Internal Server Error for url: https://endpoint-ashq-818-1-7f03ffa7-7i3yxzspbq-ew.a.run.app/cairo_run\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "500 Server Error: Internal Server Error for url: https://endpoint-ashq-818-1-7f03ffa7-7i3yxzspbq-ew.a.run.app/cairo_run",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 31\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE : \u001b[39m\u001b[38;5;132;01m% f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m(rmse))\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, proof_id\n\u001b[0;32m---> 31\u001b[0m \u001b[43mexecution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 20\u001b[0m, in \u001b[0;36mexecution\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecution\u001b[39m():\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# The input data type should match the model's expected input\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# input = np.array([[0.980643, 0.979649, 0.975971, 0.974366, 0.970623, 0.965317, 0.979038, 875.450182]]).astype(np.float32)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     (result, proof_id) \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMODEL_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVERSION_ID\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     23\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted value for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mflatten()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(MSE(Y_test, result))\n",
      "Cell \u001b[0;32mIn[45], line 10\u001b[0m, in \u001b[0;36mprediction\u001b[0;34m(input, model_id, version_id)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction\u001b[39m(\u001b[38;5;28minput\u001b[39m, model_id, version_id):\n\u001b[1;32m      8\u001b[0m     model \u001b[38;5;241m=\u001b[39m GizaModel(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mmodel_id, version\u001b[38;5;241m=\u001b[39mversion_id)\n\u001b[0;32m---> 10\u001b[0m     (result, proof_id) \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, proof_id\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/giza/agents/model.py:332\u001b[0m, in \u001b[0;36mGizaModel.predict\u001b[0;34m(self, input_file, input_feed, verifiable, fp_impl, custom_output_dtype, model_category, job_size, dry_run)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    331\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred in predict: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/giza/agents/model.py:296\u001b[0m, in \u001b[0;36mGizaModel.predict\u001b[0;34m(self, input_file, input_feed, verifiable, fp_impl, custom_output_dtype, model_category, job_size, dry_run)\u001b[0m\n\u001b[1;32m    294\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeployment predict error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(error_message)\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    298\u001b[0m body \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m    299\u001b[0m serialized_output \u001b[38;5;241m=\u001b[39m body[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/giza/agents/model.py:291\u001b[0m, in \u001b[0;36mGizaModel.predict\u001b[0;34m(self, input_file, input_feed, verifiable, fp_impl, custom_output_dtype, model_category, job_size, dry_run)\u001b[0m\n\u001b[1;32m    288\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri, json\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    293\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred in predict: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1020\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1021\u001b[0m     )\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://endpoint-ashq-818-1-7f03ffa7-7i3yxzspbq-ew.a.run.app/cairo_run"
     ]
    }
   ],
   "source": [
    "from giza.agents.model import GizaModel\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "MODEL_ID = 818  # Update with your model ID\n",
    "VERSION_ID = 1  # Update with your version ID\n",
    "\n",
    "def prediction(input, model_id, version_id):\n",
    "    model = GizaModel(id=model_id, version=version_id)\n",
    "\n",
    "    (result, proof_id) = model.predict(\n",
    "        input_feed={'input': input}, verifiable=True\n",
    "    )\n",
    "\n",
    "    return result, proof_id\n",
    "\n",
    "def execution():\n",
    "    # The input data type should match the model's expected input\n",
    "    # input = np.array([[0.980643, 0.979649, 0.975971, 0.974366, 0.970623, 0.965317, 0.979038, 875.450182]]).astype(np.float32)\n",
    "\n",
    "    (result, proof_id) = prediction(input, MODEL_ID, VERSION_ID)\n",
    "\n",
    "    print(\n",
    "        f\"Predicted value for input {input.flatten()[0]} is {result[0].flatten()[0]}\")\n",
    "    \n",
    "    rmse = np.sqrt(MSE(Y_test, result))\n",
    "    print(\"RMSE : % f\" %(rmse))\n",
    "\n",
    "    return result, proof_id\n",
    "\n",
    "\n",
    "execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[\u001b[0m\u001b[33mgiza\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m14:21:22\u001b[0m.\u001b[1;36m946\u001b[0m\u001b[1m]\u001b[0m Getting logs for endpoint \u001b[1;36m371\u001b[0m ‚úÖ \n",
      "\u001b[2m2024-06-14T08:45:11.247679Z\u001b[0m \u001b[32m INFO\u001b[0m \u001b[2morion_runner\u001b[0m\u001b[2m:\u001b[0m ‚úÖ Sierra program downloaded successfully!\n",
      "\u001b[2m2024-06-14T08:45:11.247758Z\u001b[0m \u001b[32m INFO\u001b[0m \u001b[2morion_runner\u001b[0m\u001b[2m:\u001b[0m üöÄ Server running on 0.0.0.0:8080\n",
      "Default STARTUP TCP probe succeeded after 1 attempt for container \"orion-runner-1\" on port 8080.\n",
      "\u001b[2m2024-06-14T08:45:43.948874Z\u001b[0m \u001b[32m INFO\u001b[0m \u001b[2morion_runner\u001b[0m\u001b[2m:\u001b[0m üîß Running Sierra program with request ID: fd3e370210494a87bd26404ce59b76d6\n",
      "The error: Program panicked with [Felt(FieldElement { value: UnsignedInteger { limbs: [153902630003410548, 18443949052653605432, 14829000198995122502, 11775634334075962405] } })]\n",
      "\u001b[2m2024-06-14T08:45:45.236224Z\u001b[0m \u001b[31mERROR\u001b[0m \u001b[2morion_runner::handlers\u001b[0m\u001b[2m:\u001b[0m ‚õîÔ∏è Failed to run Sierra program: Program panicked with [Felt(FieldElement { value: UnsignedInteger { limbs: [153902630003410548, 18443949052653605432, 14829000198995122502, 11775634334075962405] } })]\n",
      "\u001b[2m2024-06-14T08:45:45.236284Z\u001b[0m \u001b[31mERROR\u001b[0m \u001b[2morion_runner\u001b[0m\u001b[2m:\u001b[0m ‚õîÔ∏è Error processing request: CairoRunnerFailed\n",
      "\u001b[2m2024-06-14T08:49:32.394093Z\u001b[0m \u001b[32m INFO\u001b[0m \u001b[2morion_runner\u001b[0m\u001b[2m:\u001b[0m üîß Running Sierra program with request ID: 000ea4b111aa46f8a460a90f916b7a11\n",
      "The error: Program panicked with [Felt(FieldElement { value: UnsignedInteger { limbs: [153902630003410548, 18443949052653605432, 14829000198995122502, 11775634334075962405] } })]\n",
      "\u001b[2m2024-06-14T08:49:33.624461Z\u001b[0m \u001b[31mERROR\u001b[0m \u001b[2morion_runner::handlers\u001b[0m\u001b[2m:\u001b[0m ‚õîÔ∏è Failed to run Sierra program: Program panicked with [Felt(FieldElement { value: UnsignedInteger { limbs: [153902630003410548, 18443949052653605432, 14829000198995122502, 11775634334075962405] } })]\n",
      "\u001b[2m2024-06-14T08:49:33.624517Z\u001b[0m \u001b[31mERROR\u001b[0m \u001b[2morion_runner\u001b[0m\u001b[2m:\u001b[0m ‚õîÔ∏è Error processing request: CairoRunnerFailed\n"
     ]
    }
   ],
   "source": [
    "!giza endpoints logs -e {371} "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
